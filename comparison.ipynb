{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection.detection import anonymize_on_video, cascade_detect_image\n",
    "from existing.viola.viola import viola_anonymize_on_video, viola_detect_on_img\n",
    "from existing.mtcnn.mtcnn import mtcnn_anonymize_on_video, mtcnn_detect_on_img\n",
    "from existing.ssd.ssd import ssd_detect_on_video, ssd_detect_on_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection on image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'WIDER_train\\images/6--Funeral/6_Funeral_Funeral_6_14.jpg'\n",
    "file2 = 'WIDER_train\\images/35--Basketball/35_Basketball_Basketball_35_98.jpg'\n",
    "test_files = [file1, file2]\n",
    "\n",
    "for i in range(2):\n",
    "    viola_detect_on_img(test_files[i], True, f\"test_images/test_viola{i+1}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    mtcnn_detect_on_img(test_files[i], True, f\"test_images/test_mtcnn{i+1}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    ssd_detect_on_img(test_files[i], True, f\"test_images/test_ssd{i+1}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    cascade_detect_image(test_files[i], True, f\"test_images/test_cascade{i+1}.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define the path to the validation set and annotations\n",
    "val_path = 'WIDER_val'\n",
    "annotations_path = 'wider_face_split/wider_face_val_bbx_gt.txt'\n",
    "\n",
    "# Create a list of file paths for the images and annotations\n",
    "image_paths = []\n",
    "annotation_boxes = []\n",
    "current_image_path = \"\"\n",
    "with open(annotations_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line.endswith('.jpg'):\n",
    "            current_image_path = os.path.join(val_path, 'images', line)\n",
    "            image_paths.append(current_image_path)\n",
    "        else:\n",
    "            if line != \"\":\n",
    "                num_of_bbx = int(line)\n",
    "                current_annotation_boxes = []\n",
    "                for i in range(num_of_bbx):\n",
    "                    next_line = file.readline()\n",
    "                    x1, y1, w, h, _, _, _, _, _, _ = list(map(int, next_line.strip().split()))\n",
    "                    current_annotation_boxes.append((x1, y1, x1+w, y1+h))\n",
    "                annotation_boxes.append(current_annotation_boxes)\n",
    "\n",
    "random_indices = random.sample(range(len(image_paths)), 100)\n",
    "sample_image_paths = [image_paths[i] for i in random_indices]\n",
    "sample_annotation_boxes = [annotation_boxes[i] for i in random_indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for Viola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Viola-Jones cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Define some variables to keep track of the counts\n",
    "total_faces = 0\n",
    "detected_faces = 0\n",
    "false_negatives = 0\n",
    "false_positives = 0\n",
    "\n",
    "# Iterate over all the images and annotations\n",
    "for i in range(len(sample_image_paths)):\n",
    "    # Read the image\n",
    "    image = cv2.imread(sample_image_paths[i])\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Get the bounding boxes for all faces in the image\n",
    "    total_faces += len(sample_annotation_boxes[i])\n",
    "\n",
    "    # Detect faces in the image using the classifier\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    detected_faces += len(faces)\n",
    "\n",
    "        # Compare the detections with the annotation boxes\n",
    "    for (x, y, w, h) in faces:\n",
    "        matched = False\n",
    "        for (xmin, ymin, xmax, ymax) in sample_annotation_boxes[i]:\n",
    "            if (xmin <= x <= xmax) and (ymin <= y <= ymax):\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            false_positives += 1\n",
    "\n",
    "    # Count false negatives\n",
    "    for (xmin, ymin, xmax, ymax) in sample_annotation_boxes[i]:\n",
    "        matched = False\n",
    "        for (x, y, w, h) in faces:\n",
    "            if (xmin <= x <= xmax) and (ymin <= y <= ymax):\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            false_negatives += 1\n",
    "\n",
    "# Compute the false negative ratio\n",
    "false_negative_ratio = false_negatives / total_faces\n",
    "print('False negative ratio for Viola-Jones:', false_negative_ratio)\n",
    "\n",
    "# Compute the false positive ratio\n",
    "false_positive_ratio = false_positives / total_faces\n",
    "print('False positive ratio for Viola-Jones:', false_positive_ratio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for our cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import predict\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('best_model.h5', compile=False)\n",
    "\n",
    "# Load the Viola-Jones cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Define some variables to keep track of the counts\n",
    "total_faces = 0\n",
    "detected_faces = 0\n",
    "cnn_approved_faces = 0\n",
    "false_negatives = 0\n",
    "false_positives = 0\n",
    "\n",
    "# Iterate over all the images and annotations\n",
    "for i in range(len(sample_image_paths)):\n",
    "    # Read the image\n",
    "    image = cv2.imread(sample_image_paths[i])\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Get the bounding boxes for all faces in the image\n",
    "    total_faces += len(sample_annotation_boxes[i])\n",
    "\n",
    "    # Detect faces in the image using the classifier\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    detected_faces += len(faces)\n",
    "    cnn_faces = []\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        result = predict(model, gray[y:y+h, x:x+w])\n",
    "        if result == 1:\n",
    "            cnn_approved_faces += 1\n",
    "            cnn_faces.append((x, y, w, h))\n",
    "\n",
    "        # Compare the detections with the annotation boxes\n",
    "    for (x, y, w, h) in cnn_faces:\n",
    "        matched = False\n",
    "        for (xmin, ymin, xmax, ymax) in sample_annotation_boxes[i]:\n",
    "            if (xmin <= x <= xmax) and (ymin <= y <= ymax):\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            false_positives += 1\n",
    "\n",
    "    # Count false negatives\n",
    "    for (xmin, ymin, xmax, ymax) in sample_annotation_boxes[i]:\n",
    "        matched = False\n",
    "        for (x, y, w, h) in cnn_faces:\n",
    "            if (xmin <= x <= xmax) and (ymin <= y <= ymax):\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            false_negatives += 1\n",
    "\n",
    "# Compute the false negative ratio\n",
    "false_negative_ratio = false_negatives / total_faces\n",
    "print('False negative ratio for Viola-CNN Cascade:', false_negative_ratio)\n",
    "\n",
    "# Compute the false positive ratio\n",
    "false_positive_ratio = false_positives / total_faces\n",
    "print('False positive ratio for Viola-CNN Cascade:', false_positive_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
